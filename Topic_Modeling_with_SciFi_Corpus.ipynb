{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic Modeling with SciFi Corpus.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "40KVswYbunE3",
        "f4qStMOwuvYK",
        "MI34VMFq801e"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkane968/Extracted-Features/blob/master/Topic_Modeling_with_SciFi_Corpus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXOw5gPaRLuQ"
      },
      "source": [
        "# Topic Modeling the SciFi Corpus Using Gensim and pyLDAvis\n",
        "\n",
        "Adapted from: https://github.com/hawc2/text-analysis-with-python/blob/master/Topic_Modeling.ipynb "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxEMrysjRHwB"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OJjCRA2y8_fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40KVswYbunE3"
      },
      "source": [
        "# Upload Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC1izyiZG8EJ"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlidT20Tu6jj"
      },
      "source": [
        "# Convert CSV to Data Frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUM-atjwy0mm"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(io.StringIO(uploaded['output (2).csv'].decode('utf-8')))\n",
        "df"
      ],
      "metadata": {
        "id": "iQAUVWZ19lsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo-GqUxGy_dY"
      },
      "source": [
        "data = df.Text.values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rxXIUj2e2Xf"
      },
      "source": [
        "### View Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkpYoGOOe0HB"
      },
      "source": [
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EocrECQchTEF"
      },
      "source": [
        "%load_ext google.colab.data_table \n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7B4L5MRRFJH"
      },
      "source": [
        "# Clean Texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjRgCvQRfOOE"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKiUtIFysZWT"
      },
      "source": [
        "# A simple way to add further stop words\n",
        "#stop_words.append('movie')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7B4DTzZnIJ6"
      },
      "source": [
        "!pip3 install spacy\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gh0U8nAimp2L"
      },
      "source": [
        "import spacy\n",
        "import en_core_web_lg\n",
        "nlp = en_core_web_lg.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YO_PUA0uC-F"
      },
      "source": [
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.utils import simple_preprocess"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74qiZ1JPjsQh"
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQXKsWbxrsUg"
      },
      "source": [
        "data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
        "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
        "data = [re.sub(\"\\'\", \"\", sent) for sent in data]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFPfCl6nHHjT"
      },
      "source": [
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "      yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "data_words = list(sent_to_words(data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9saf7oBhoRdy"
      },
      "source": [
        "print(data_words[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOtbz8fXfgCt"
      },
      "source": [
        "bigram = gensim.models.Phrases(data_words, min_count=1, threshold=100)\n",
        "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4qFCAGQfgvA"
      },
      "source": [
        "def remove_stopwords(texts):\n",
        "   return [[word for word in simple_preprocess(str(doc))\n",
        "if word not in stop_words] for doc in texts]\n",
        "\n",
        "def make_bigrams(texts):\n",
        "   return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "#def make_trigrams(texts):\n",
        "#   return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "   texts_out = []\n",
        "   for sent in texts:\n",
        "     doc = nlp(\" \".join(sent))\n",
        "     texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "   return texts_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRMeqTfHkey6"
      },
      "source": [
        "data_words_nostops = remove_stopwords(data_words)\n",
        "data_words_bigrams = make_bigrams(data_words_nostops)\n",
        "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=[\n",
        "   'NOUN', 'ADJ', 'VERB', 'ADV'\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctV_0V95kj1p"
      },
      "source": [
        "print(data_lemmatized[:4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JXqo5CI47kE"
      },
      "source": [
        "# Building Dictionary and Corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf46pDnu4CNX"
      },
      "source": [
        "id2word = corpora.Dictionary(data_lemmatized)\n",
        "texts = data_lemmatized\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "print(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EExpaCS7SInJ"
      },
      "source": [
        "# Create Topic Model - Topics 20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqbXMdeAHIq5"
      },
      "source": [
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=20,\n",
        "                                           random_state=100,\n",
        "                                           update_every=2,\n",
        "                                           chunksize=100,\n",
        "                                           passes=20,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3_bC9dfS0q3"
      },
      "source": [
        "# Create Visualization (Save HTML)\n",
        "\n",
        "The easiest way to create the visualization is to reveal it in the Google Colab notebook and save it as an html file that you can view on your browser. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz2SdZiGtzcb"
      },
      "source": [
        "!pip install pyLDAvis\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models as gensimvis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKhTNneQHJ1C"
      },
      "source": [
        "vis = gensimvis.prepare(lda_model, corpus, id2word)\n",
        "\n",
        "#vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word, mds='mmds')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk7mOcrnktEp"
      },
      "source": [
        "pyLDAvis.save_html(vis, '/content/LDAviz.html')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z83wjLBgsedR"
      },
      "source": [
        "pyLDAvis.display(vis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH4WlWezsHNy"
      },
      "source": [
        "# Topic Modeling Model - 60 Topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSu3f89PsGtI"
      },
      "source": [
        "lda_model60 = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=60,\n",
        "                                           random_state=100,\n",
        "                                           update_every=2,\n",
        "                                           chunksize=100,\n",
        "                                           passes=20,\n",
        "                                           iterations=200,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7lb7hEasr9u"
      },
      "source": [
        "# Create Visualization (Save HTML)\n",
        "\n",
        "The easiest way to create the visualization is to reveal it in the Google Colab notebook and save it as an html file that you can view on your browser. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lst_Wcwsr-J"
      },
      "source": [
        "vis60 = pyLDAvis.gensim.prepare(lda_model60, corpus, id2word)\n",
        "#vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word, mds='mmds')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJBuBBcGsr-Q"
      },
      "source": [
        "pyLDAvis.save_html(vis60, '/content/LDAviz60.html')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LnUVVOJsr-X"
      },
      "source": [
        "pyLDAvis.display(vis60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI34VMFq801e"
      },
      "source": [
        "# Serve Visualization in Browser\n",
        "\n",
        "You can also serve the visualization locally in the browser using the below chunk of code. Beware that caching in your browser and other issues, such as ad-blockers, may require some debugging to get this working on your machine. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn8XNwM58zrM"
      },
      "source": [
        "#pyLDAvis.enable_notebook()\n",
        "#pyLDAvis.show(vis)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}