{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generating and Evaluating Topic Models (Colab).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOF18JzHVtZ8SVb2vgLlmTz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkane968/Extracted-Features/blob/master/Generating_and_Evaluating_Topic_Models_(Colab).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "Below, Gensim is used to create LDA topic models of a pre-loaded dataframe of texts. Methods for evaluating topic coherence and analyzing topic output are also demonstrated. \n",
        "\n",
        "This code is adapted from [Intro to Topic Modeling with Gensim and pyLDAvis](https://github.com/hawc2/text-analysis-with-python/blob/master/Topic_Modeling.ipynb) and works well with input from from the Text Sectioning and Disaggregation code from [this repository](https://github.com/SF-Nexus/Extracted-Features/blob/main/Text_Sectioning_and_Disaggregation_in_Python.ipynb)\n",
        "\n"
      ],
      "metadata": {
        "id": "g8A3mVdwoQ7Y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfm_YfxIRWjD"
      },
      "source": [
        "#Install Packages\n",
        "This code requires three main packages:\n",
        "- **NLTK:** Cleaning disaggregated data\n",
        "- **Gensim:** Preprocessing data and creating word embeddings, coherence models and topic models\n",
        "- **LDAvis:** Visualizing topic models\n",
        "\n",
        "Several other packages for wrangling and processing the data, such as io and pandas, will also be installed. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNIhKdGeRWH1"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZkNZc4lRhTL"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bG2pqtVN_DFK"
      },
      "outputs": [],
      "source": [
        "!pip install pyLDAvis\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjAj_KoORnfS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import io\n",
        "import re\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Retrieve and Convert Corpus to Data Frame\n",
        "\n",
        "This code requires the upload of a previously created dataframe which contains a corpus of disaggregated texts. For optimal use, this dataframe should also contain labels associated with each text (e.g. book or chapter numbers).\n"
      ],
      "metadata": {
        "id": "E1rFfgBuovwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#View dataframe as Colab data table\n",
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()\n",
        "df.head()"
      ],
      "metadata": {
        "id": "XY5JF2a-o_wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "aR9rfSbuo5lZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert csv to dataframe\n",
        "df = pd.read_csv(io.StringIO(uploaded['chapters_bag_of_words_output (1).csv'].decode('utf-8')))\n",
        "df"
      ],
      "metadata": {
        "id": "TWXfkD3co6LZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop any empty cells\n",
        "df = df.dropna()\n",
        "df"
      ],
      "metadata": {
        "id": "zQESwCtSo8n0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add values in Text column to new list (for further cleaning)\n",
        "data = df.Text.values.tolist()"
      ],
      "metadata": {
        "id": "hL9UAlNVo-Mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean Texts\n",
        "Below are several preprocessing measures to help improve quality of text used for the topic model. Some may or may not be useful depending on specifications of corpus or goals of topic modeling:\n",
        "- **Stopword Removal:** Removes globally common words from corpus which may skew topics; some stopwords may be useful for analysis and some studies show that removing more than the top 10 most common words does not significantly impact topic model results \n",
        "- **Bigrams/Trigram Modeling:** Recognizes common 2- and 3-word phrases to prevent disambiguation (e.g. spaceship vs. space, ship); may misidentify phrases especially in corpora with large/uncommon vocabularies like sci-fi\n",
        "- **Lemmatization:** Transforms words to root form to aid recognition; some studies show may be redundant, unnecessary or even inaccurate in conflating differing words with same root meanings \n",
        "\n",
        "*Read More:*\n",
        "\n",
        "https://maria-antoniak.github.io/2022/07/27/topic-modeling-for-the-people.html\n",
        "\n",
        "https://towardsdatascience.com/6-tips-to-optimize-an-nlp-topic-model-for-interpretability-20742f3047e2\n"
      ],
      "metadata": {
        "id": "jSB23VIKpHgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define list of stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "# Add further stopwords by simply \"appending\" desired words to dictionary\n",
        "#stop_words.append('CHAPTER')"
      ],
      "metadata": {
        "id": "MQUc8j3cpG38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove punctuation\n",
        "data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
        "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
        "data = [re.sub(\"\\'\", \"\", sent) for sent in data]"
      ],
      "metadata": {
        "id": "DpJErEdLpYln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define function to perform simple preprocessing on text\n",
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "      yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations"
      ],
      "metadata": {
        "id": "MyNO2S_7pbhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run processing function on texts\n",
        "data_words = list(sent_to_words(data))\n",
        "#print(data_words[:1])"
      ],
      "metadata": {
        "id": "5M668e3upd6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define stopword removal\n",
        "def remove_stopwords(texts):\n",
        "   return [[word for word in simple_preprocess(str(doc))\n",
        "if word not in stop_words] for doc in texts]\n",
        "\n",
        "#Define function to make bigrams\n",
        "def make_bigrams(texts):\n",
        "   return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "#def make_trigrams(texts):\n",
        "#   return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "\n",
        "#Define function to lemmatize texts\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "   texts_out = []\n",
        "   for sent in texts:\n",
        "     doc = nlp(\" \".join(sent))\n",
        "     texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "   return texts_out"
      ],
      "metadata": {
        "id": "KFMsV5zvpef_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define bigram and trigram models\n",
        "bigram = gensim.models.Phrases(data_words, min_count=1, threshold=100)\n",
        "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)"
      ],
      "metadata": {
        "id": "ULprlcmDpgvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run functions to remove stopwords, make bigrams, and lemmatize text\n",
        "data_words = remove_stopwords(data_words)\n",
        "#data_words_bigrams = make_bigrams(data_nostops)\n",
        "#data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "#print(data_lemmatized[:4])"
      ],
      "metadata": {
        "id": "wOX5gnsNpi4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_words"
      ],
      "metadata": {
        "id": "2Gt-HgRmpkdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Dictionary and Corpus\n",
        "Once the dataset is cleaned, two inputs must be created to run the topic model. Creating the dictionary maps every word in the corpus with a unique id number. The variable corpus is calculated by determining the frequency of each word in the document. Another optional cleaning measure can be used here--removing words that are extremely rare (existing in < n number of texts) or common (existing in > n number of texts).  "
      ],
      "metadata": {
        "id": "RKl-yFDEplFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dictionary\n",
        "from gensim.corpora import Dictionary\n",
        "\n",
        "# Create a dictionary representation of the documents.\n",
        "dictionary = Dictionary(data_words)\n",
        "\n",
        "#Calculate term document frequency for each word in dataset\n",
        "corpus = [dictionary.doc2bow(doc) for doc in data_words]\n",
        "corpus"
      ],
      "metadata": {
        "id": "hNjsLRstpnho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OPTIONAL cleaning: filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
        "#dictionary.filter_extremes(no_below=2, no_above=0.8)"
      ],
      "metadata": {
        "id": "H0NGM1AAptZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get number of unique tokens and documents\n",
        "print('Number of unique tokens: %d' % len(dictionary))\n",
        "print('Number of documents: %d' % len(corpus))"
      ],
      "metadata": {
        "id": "LgT-OGF6qGbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find Optimal Number of Topics\n",
        "\n",
        "Calculating topic model coherence (i.e. similarity between the highest-scoring words in each topic) is one way to assess the optimal number of topics to use when creating and visualizing topic models. Below are two methods of calculating coherence: **C_V coherence**, which is calculated based on word co-occurences, and **U_Mass coherence**, which is calculated based on how frequently documents containing high-scoring words co-occur in the corpus. Both have been used in prior research and either may yield better results, depending on corpus specifications.\n",
        "\n",
        "Additional readings: \n",
        "\n",
        "https://aclanthology.org/D12-1087.pdf \n",
        "\n",
        "https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0\n",
        "\n",
        "https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html"
      ],
      "metadata": {
        "id": "SaICbjTHqKrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define list for model and coherence values\n",
        "coherence = []\n",
        "\n",
        "#Find coherence for set range of models and append to list\n",
        "for k in range(2,200):\n",
        "    print('Round: '+str(k))\n",
        "    Lda = gensim.models.ldamodel.LdaModel\n",
        "    ldamodel = Lda(corpus, num_topics=k, \\\n",
        "               id2word = dictionary, eval_every = None)\n",
        "    \n",
        "    cm = gensim.models.coherencemodel.CoherenceModel(\\\n",
        "         model=ldamodel, texts=data_words,\\\n",
        "         dictionary=dictionary, coherence='c_v')   \n",
        "                                                \n",
        "    coherence.append((k,cm.get_coherence()))"
      ],
      "metadata": {
        "id": "nz4XfXH3qLYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transpose coherence data\n",
        "x, y = np.array(coherence).T\n",
        "  \n",
        "      \n",
        "# plot our list in X,Y coordinates\n",
        "optimal, = plt.plot(x, y)\n",
        "plt.xlabel(\"Num Topics\")\n",
        "plt.ylabel(\"Coherence score\")\n",
        "plt.legend((\"coherence_values\"), loc='best')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qmMoYFoGqRpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get coherence score for each num topics sorted from highest to lowest\n",
        "#Highest value will be optimal number of topics\n",
        "Data = {'Num Topics': optimal.get_xdata(), 'Coherence': optimal.get_ydata()}\n",
        "type(Data)\n",
        "df_optimal = pd.DataFrame.from_dict(Data)\n",
        "df_optimal.sort_values(by='Coherence',ascending=False).head()"
      ],
      "metadata": {
        "id": "YNgtOOLPqUnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## U_Mass Coherence Calculation\n",
        "The function below calculates U_Mass coherence scores of n topic models run based on set parameters. Coherence is calculated on a range of -14 < x < 14 where lower-scoring models are more coherent. For example, a model with a score of -.4 is less coherent than a model with a -.9 score. \n"
      ],
      "metadata": {
        "id": "vD_QrVa9qXZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define list for model and coherence values\n",
        "coherence2 = []\n",
        "\n",
        "#Find coherence for set range of models and append to list\n",
        "for k in range(2,200):\n",
        "    print('Round: '+str(k))\n",
        "    Lda = gensim.models.ldamodel.LdaModel\n",
        "    ldamodel = Lda(corpus, num_topics=k, \\\n",
        "               id2word = dictionary, eval_every = None)\n",
        "    \n",
        "    cm = gensim.models.coherencemodel.CoherenceModel(\\\n",
        "         model=ldamodel, texts=data_words,\\\n",
        "         dictionary=dictionary, coherence='u_mass')   \n",
        "                                                \n",
        "    coherence2.append((k,cm.get_coherence()))"
      ],
      "metadata": {
        "id": "DD-_tzTSqVNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transpose coherence data\n",
        "x, y = np.array(coherence2).T\n",
        "        \n",
        "# plot our list in X,Y coordinates\n",
        "optimal2, = plt.plot(x, y)\n",
        "plt.xlabel(\"Num Topics\")\n",
        "plt.ylabel(\"Coherence score\")\n",
        "plt.legend((\"coherence_values\"), loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-wsezLVzqagG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get coherence score for each num topics sorted from highest to lowest\n",
        "#Lowest value will be optimal number of topics\n",
        "Data = {'Num Topics': optimal2.get_xdata(), 'Coherence': optimal2.get_ydata()}\n",
        "type(Data)\n",
        "df_optimal2 = pd.DataFrame.from_dict(Data)\n",
        "df_optimal2.sort_values(by='Coherence',ascending=True).head()"
      ],
      "metadata": {
        "id": "_-DBZAZcqcZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Topic Models with Optimal Parameters\n",
        "Input the parameters of the topic model and run. The model has multiple parameters, including: \n",
        "- num_topics: Number of topics the model will generate (default = 100)\n",
        "- chunksize: Number of documents processed at a time (default = 2000)\n",
        "- passes: Number of times model is trained on corpus (default = 1)\n",
        "- iterations: Number of times model \"loops\" over each document (default = 50)\n",
        "\n",
        "Calculating coherence (above) helps determine topic number, and other methods can be used to determine appropriate values for the other parameters. \n",
        "\n",
        "**Chunk size:** Setting chunk size to a larger number than that of documents in the model ensures that all documents are processed at once (though this requires enough memory space). \n",
        "\n",
        "**Passes and Iterations:** A common way to determine the best number of passes and iterations is by training a topic model and checking the \"log\" to see the document convergence rate (what percentage of topic/word assignments attain stability). If convergence is low, increase number of passes and interations. \n",
        "\n",
        "In general, as chunksize increases, passes and iterations should increase as well. Also keep in mind that corpus size may effect number of topics--in the cases of smaller corpora, using too many topics will likely make them too general OR too limited to the context of only one text. Consider running multiple models and comparing coherence, perplexity, and top words per topic. \n",
        "\n",
        "Additional reading: \n",
        "\n",
        "https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html\n",
        "\n",
        "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#12buildingthetopicmodel"
      ],
      "metadata": {
        "id": "8yPbLlJ8qfe3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import logging to gauge passes and iterations; will output file to working directory\n",
        "import logging\n",
        "logging.basicConfig(filename='gensim.log',\n",
        "                    format=\"%(asctime)s:%(levelname)s:%(message)s\",\n",
        "                    level=logging.INFO)"
      ],
      "metadata": {
        "id": "vwbCuH_RqeSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train LDA model.\n",
        "from gensim.models import LdaModel\n",
        "\n",
        "# Set training parameters.\n",
        "num_topics = 99\n",
        "chunksize = 10000\n",
        "passes = 200\n",
        "iterations = 400\n",
        "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
        "\n",
        "# Make an index to word dictionary.\n",
        "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
        "id2word = dictionary.id2token\n",
        "\n",
        "lda_model = LdaModel(\n",
        "    corpus=corpus,\n",
        "    id2word=id2word,\n",
        "    chunksize=chunksize,\n",
        "    alpha='auto',\n",
        "    eta='auto',\n",
        "    iterations=iterations,\n",
        "    num_topics=num_topics,\n",
        "    passes=passes,\n",
        "    eval_every=1\n",
        ")"
      ],
      "metadata": {
        "id": "kLUw7ehyqi6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Perplexity\n",
        "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Compute C_V Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_words, dictionary=dictionary, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "metadata": {
        "id": "TCYxkKvFqnpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Examine Topic Model Output\n",
        "Once the model has been run, it is possible to retrieve the top words in each topic and visualing the model. These are methods can help further assess model coherence and point to future directions for analysis:\n",
        "- **Top Words Per Topic:** Evaluate to what extent each topic contains semantically similar words, how/why these words might be meaningful in context of corpus\n",
        "- **Visualizations:** Determine topic relatedness (how far apart topic circles are on plane) and topic prevalence (how large circles are corresponds to topic prevaence in corpus)\n",
        "\n",
        "Additional reading: \n",
        "\n",
        "https://towardsdatascience.com/6-tips-to-optimize-an-nlp-topic-model-for-interpretability-20742f3047e2\n",
        "\n",
        "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#15visualizethetopicskeywords\n",
        "\n",
        "https://www.machinelearningplus.com/nlp/topic-modeling-visualization-how-to-present-results-lda-models/\n"
      ],
      "metadata": {
        "id": "5qrKa1r9qqDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Print n number of words in each topic\n",
        "for idx, topic in lda_model.print_topics(num_words=8):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "metadata": {
        "id": "OXD1btIcqpRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#OPTIONAL: Define word cloud function\n",
        "def create_wordcloud(model, topic):\n",
        "    text = {word: value for word, value in model.show_topic(topic)}\n",
        "    wc = WordCloud(background_color=\"white\", max_words=1000)\n",
        "    wc.generate_from_frequencies(text)\n",
        "    plt.imshow(wc, interpolation=\"bilinear\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Topic\" + \" \"+ str(topic))\n",
        "    plt.show()\n",
        "    \n",
        "#Ignore depreciation warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#Create word clouds\n",
        "for i in range(1,num_topics):\n",
        "    create_wordcloud(lda_model, topic=i)"
      ],
      "metadata": {
        "id": "tgE_thMkqsPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create visualization of topic model above \n",
        "%matplotlib inline\n",
        "import pyLDAvis.gensim_models\n",
        "vis = pyLDAvis.gensim_models.prepare(topic_model=lda_model, corpus=corpus, dictionary=dictionary)\n",
        "pyLDAvis.enable_notebook()\n",
        "pyLDAvis.display(vis)"
      ],
      "metadata": {
        "id": "i6aQBQLhqx6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save visualization as html output\n",
        "pyLDAvis.save_html(vis, '/content/LDAviz.html')"
      ],
      "metadata": {
        "id": "iluH9y6vq3nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find Top Topics Per Document\n",
        "\n",
        "Find the topic with highest percentage in each document in corpus. \n",
        "\n",
        "Additional reading: \n",
        "https://towardsdatascience.com/topic-modelling-in-python-with-spacy-and-gensim-dc8f7748bdbf"
      ],
      "metadata": {
        "id": "gHTWRPDgq8cj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define function that retrieves dominant topic for each document and puts in dataframe\n",
        "def format_topics_texts(ldamodel=None, corpus=corpus, texts=data):\n",
        "    # Init output\n",
        "    text_topics_df = pd.DataFrame()\n",
        "\n",
        "    # Get main topic in each document\n",
        "    for i, row_list in enumerate(ldamodel[corpus]):\n",
        "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
        "        # print(row)\n",
        "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
        "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
        "        for j, (topic_num, prop_topic) in enumerate(row):\n",
        "            if j == 0:  # => dominant topic\n",
        "                wp = ldamodel.show_topic(topic_num)\n",
        "                topic_keywords = \", \".join([word for word, prop in wp])\n",
        "                text_topics_df = text_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
        "            else:\n",
        "                break\n",
        "    text_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
        "\n",
        "    # Add original text to the end of the output\n",
        "    contents = pd.Series(texts)\n",
        "    text_topics_df = pd.concat([text_topics_df, contents], axis=1)\n",
        "    return(text_topics_df)"
      ],
      "metadata": {
        "id": "dTI7k5d5q7t7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run dominant topic function on corpus\n",
        "df_topic_texts_keywords = format_topics_texts(ldamodel=lda_model, corpus=corpus, texts=data_words)\n",
        "\n",
        "# Format\n",
        "df_dominant_topic = df_topic_texts_keywords.reset_index()\n",
        "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
        "df_dominant_topic.head(10)"
      ],
      "metadata": {
        "id": "hAg9AV5cq_YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find Top Documents Per Topic\n",
        "Calculate the top documents attributed to each topic in the model. \n",
        "\n",
        "Additional reading:\n",
        "\n",
        "https://stackoverflow.com/questions/63777101/topic-wise-document-distribution-in-gensim-lda\n",
        "\n",
        "https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/topic_methods.ipynb \n",
        "\n",
        "https://www.machinelearningplus.com/nlp/topic-modeling-visualization-how-to-present-results-lda-models/#7.-The-most-representative-sentence-for-each-topic "
      ],
      "metadata": {
        "id": "Utjpsi0irCED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Add Book + Chapter labels to dataframe for easier ID\n",
        "doc_names = df['Book + Chapter']\n",
        "df_topic_texts_keywords = df_topic_texts_keywords.join(doc_names)"
      ],
      "metadata": {
        "id": "Mc2d9WPlrGdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get most representative text for each topic \n",
        "#Display setting to show more characters in column\n",
        "pd.options.display.max_colwidth = 100\n",
        "\n",
        "#Create new dataframe and group topic keywords by dominant topic column\n",
        "topics_sorted_df = pd.DataFrame()\n",
        "sent_topics_outdf_grpd = df_topic_texts_keywords.groupby('Dominant_Topic')\n",
        "\n",
        "#Sort data by percent contribution and select highest n values for each topic\n",
        "for i, grp in sent_topics_outdf_grpd:\n",
        "    topics_sorted_df = pd.concat([topics_sorted_df, \n",
        "                                             grp.sort_values(['Perc_Contribution'], ascending=False).head(1)], \n",
        "                                            axis=0)"
      ],
      "metadata": {
        "id": "IuD9T797rJAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset Index of new df\n",
        "topics_sorted_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Format\n",
        "topics_sorted_df.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Representative Text\", \"Text Name\"]\n",
        "topics_sorted_df = topics_sorted_df.reindex(columns=['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text Name\", \"Representative Text\"])\n",
        "# Show\n",
        "topics_sorted_df.head()"
      ],
      "metadata": {
        "id": "aWK-vZXdrK95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Future step: Gensim word embeddings!\n",
        "\n",
        "https://towardsdatascience.com/a-beginners-guide-to-word-embedding-with-gensim-word2vec-model-5970fa56cc92 \n",
        "\n",
        "https://www.shanelynn.ie/word-embeddings-in-python-with-spacy-and-gensim/"
      ],
      "metadata": {
        "id": "INKONFXkrM_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sources\n",
        "\n",
        "**More Examples of Topic Modeling Research:**\n",
        "\n",
        "*   http://www.digitalhumanities.org/dhq/vol/11/2/000291/000291.html\n",
        "*   http://www.cs.columbia.edu/~blei/papers/Blei2011.pdf\n",
        "*   https://maria-antoniak.github.io/resources/2019_cscw_birth_stories.pdf \n",
        "\n",
        "**More Topic Modeling Tools:**\n",
        "\n",
        "*   https://github.com/polsci/colab-gensim-mallet/blob/master/topic-modeling-with-colab-gensim-mallet.ipynb\n",
        "*   https://github.com/laurejt/authorless-tms \n",
        "*   https://colab.research.google.com/github/kldarek/skok/blob/master/_notebooks/2021-05-27-Topic-Models-Introduction.ipynb\n"
      ],
      "metadata": {
        "id": "0KYWtDBrrQrl"
      }
    }
  ]
}